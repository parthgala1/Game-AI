{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect your GPU to the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Watch this video to get basic knowledge [Youtube](https://youtu.be/YmDaqXMIoeY?si=JdFTtz_G7s9Ni9In.).\n",
    "\n",
    "Follow the Youtube Video for around 3 minutes uptill the datasets part.\n",
    "\n",
    "For the documantation follow This [Link](https://shawnhymel.com/1961/how-to-install-tensorflow-with-gpu-support-on-windows/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the required folders before running"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From The VGLC GitHub copy the processed folder.\n",
    "https://github.com/theVGLC/theVGLC\n",
    "\n",
    "Follow The folder structure: Super Mario Bros/Processed\n",
    "\n",
    "Create the `Processed` folder in the same directory as the `MarioGAN.ipynb` and add the above .txt files in this folder.\n",
    "\n",
    "Run the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:161: SyntaxWarning: invalid escape sequence '\\T'\n",
      "<>:161: SyntaxWarning: invalid escape sequence '\\T'\n",
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_3372\\48845432.py:161: SyntaxWarning: invalid escape sequence '\\T'\n",
      "  directory_path = '.\\TheVGLC\\Super Mario Bros\\Processed'\n",
      "d:\\Deep Learning\\myenv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "d:\\Deep Learning\\myenv\\Lib\\site-packages\\keras\\src\\layers\\activations\\leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 733ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Deep Learning\\myenv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [D loss: 0.6728358268737793, acc.: 82.03125%] [G loss: [array(0.6797489, dtype=float32), array(0.6797489, dtype=float32), array(0.640625, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step\n",
      "Generated level saved to ./generated_level_0.txt\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator at 0x000001F315E6AC00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator at 0x000001F315EF9EE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1 [D loss: 0.6779319047927856, acc.: 68.48958730697632%] [G loss: [array(0.6803805, dtype=float32), array(0.6803805, dtype=float32), array(0.609375, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step\n",
      "2 [D loss: 0.678724467754364, acc.: 63.28125%] [G loss: [array(0.6803109, dtype=float32), array(0.6803109, dtype=float32), array(0.578125, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247ms/step\n",
      "3 [D loss: 0.6801572442054749, acc.: 60.04464626312256%] [G loss: [array(0.6813884, dtype=float32), array(0.6813884, dtype=float32), array(0.5625, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step\n",
      "4 [D loss: 0.6805479526519775, acc.: 58.05555582046509%] [G loss: [array(0.68173754, dtype=float32), array(0.68173754, dtype=float32), array(0.55, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step\n",
      "5 [D loss: 0.6814597845077515, acc.: 56.62878751754761%] [G loss: [array(0.6825971, dtype=float32), array(0.6825971, dtype=float32), array(0.5416667, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293ms/step\n",
      "6 [D loss: 0.6824233531951904, acc.: 55.631864070892334%] [G loss: [array(0.6836029, dtype=float32), array(0.6836029, dtype=float32), array(0.53571427, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276ms/step\n",
      "7 [D loss: 0.6836224794387817, acc.: 54.895830154418945%] [G loss: [array(0.68483543, dtype=float32), array(0.68483543, dtype=float32), array(0.53125, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step\n",
      "8 [D loss: 0.6852719783782959, acc.: 54.33006286621094%] [G loss: [array(0.68656623, dtype=float32), array(0.68656623, dtype=float32), array(0.5277778, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step\n",
      "9 [D loss: 0.6867495775222778, acc.: 53.88157367706299%] [G loss: [array(0.68807924, dtype=float32), array(0.68807924, dtype=float32), array(0.525, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step\n",
      "10 [D loss: 0.6886487007141113, acc.: 53.51731777191162%] [G loss: [array(0.69025034, dtype=float32), array(0.69025034, dtype=float32), array(0.52272725, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step\n",
      "11 [D loss: 0.6909891366958618, acc.: 53.215575218200684%] [G loss: [array(0.6928265, dtype=float32), array(0.6928265, dtype=float32), array(0.5208333, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step\n",
      "12 [D loss: 0.6938431262969971, acc.: 52.96154022216797%] [G loss: [array(0.6957703, dtype=float32), array(0.6957703, dtype=float32), array(0.5192308, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step\n",
      "13 [D loss: 0.6968158483505249, acc.: 52.74471044540405%] [G loss: [array(0.6990123, dtype=float32), array(0.6990123, dtype=float32), array(0.51785713, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 315ms/step\n",
      "14 [D loss: 0.7002475261688232, acc.: 52.55746841430664%] [G loss: [array(0.7026278, dtype=float32), array(0.7026278, dtype=float32), array(0.51666665, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299ms/step\n",
      "15 [D loss: 0.7044183611869812, acc.: 52.39415168762207%] [G loss: [array(0.7073635, dtype=float32), array(0.7073635, dtype=float32), array(0.515625, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239ms/step\n",
      "16 [D loss: 0.7093005776405334, acc.: 52.2504448890686%] [G loss: [array(0.7124978, dtype=float32), array(0.7124978, dtype=float32), array(0.5147059, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step\n",
      "17 [D loss: 0.7147859930992126, acc.: 52.123016119003296%] [G loss: [array(0.718351, dtype=float32), array(0.718351, dtype=float32), array(0.5138889, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246ms/step\n",
      "18 [D loss: 0.7211230397224426, acc.: 52.00924873352051%] [G loss: [array(0.7252382, dtype=float32), array(0.7252382, dtype=float32), array(0.5131579, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step\n",
      "19 [D loss: 0.7279272079467773, acc.: 51.90705060958862%] [G loss: [array(0.7321373, dtype=float32), array(0.7321373, dtype=float32), array(0.5125, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step\n",
      "20 [D loss: 0.7352533340454102, acc.: 51.81474685668945%] [G loss: [array(0.7399376, dtype=float32), array(0.7399376, dtype=float32), array(0.5119048, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step\n",
      "21 [D loss: 0.743207573890686, acc.: 51.73097252845764%] [G loss: [array(0.74817586, dtype=float32), array(0.74817586, dtype=float32), array(0.5113636, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step\n",
      "22 [D loss: 0.7516173124313354, acc.: 51.65458917617798%] [G loss: [array(0.7568374, dtype=float32), array(0.7568374, dtype=float32), array(0.51086956, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step\n",
      "23 [D loss: 0.7606734037399292, acc.: 51.58466100692749%] [G loss: [array(0.7664163, dtype=float32), array(0.7664163, dtype=float32), array(0.5104167, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 248ms/step\n",
      "24 [D loss: 0.7700707912445068, acc.: 51.52040719985962%] [G loss: [array(0.77578974, dtype=float32), array(0.77578974, dtype=float32), array(0.51, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238ms/step\n",
      "25 [D loss: 0.7796795964241028, acc.: 51.46116018295288%] [G loss: [array(0.78564495, dtype=float32), array(0.78564495, dtype=float32), array(0.50961536, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step\n",
      "26 [D loss: 0.7896732091903687, acc.: 51.40635967254639%] [G loss: [array(0.7959633, dtype=float32), array(0.7959633, dtype=float32), array(0.5092593, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283ms/step\n",
      "27 [D loss: 0.7998284101486206, acc.: 51.35551691055298%] [G loss: [array(0.8060857, dtype=float32), array(0.8060857, dtype=float32), array(0.5089286, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step\n",
      "28 [D loss: 0.8099640011787415, acc.: 51.308226585388184%] [G loss: [array(0.8163375, dtype=float32), array(0.8163375, dtype=float32), array(0.5086207, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407ms/step\n",
      "29 [D loss: 0.8201116919517517, acc.: 51.26412510871887%] [G loss: [array(0.8264819, dtype=float32), array(0.8264819, dtype=float32), array(0.5083333, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406ms/step\n",
      "30 [D loss: 0.8301671743392944, acc.: 51.222896575927734%] [G loss: [array(0.836451, dtype=float32), array(0.836451, dtype=float32), array(0.5080645, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409ms/step\n",
      "31 [D loss: 0.8399162292480469, acc.: 51.18427276611328%] [G loss: [array(0.8460747, dtype=float32), array(0.8460747, dtype=float32), array(0.5078125, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404ms/step\n",
      "32 [D loss: 0.8496668934822083, acc.: 51.14802122116089%] [G loss: [array(0.8559967, dtype=float32), array(0.8559967, dtype=float32), array(0.50757575, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step\n",
      "33 [D loss: 0.8593794107437134, acc.: 51.11391544342041%] [G loss: [array(0.86561644, dtype=float32), array(0.86561644, dtype=float32), array(0.50735295, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step\n",
      "34 [D loss: 0.8691723346710205, acc.: 51.08177661895752%] [G loss: [array(0.87554175, dtype=float32), array(0.87554175, dtype=float32), array(0.50714284, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step\n",
      "35 [D loss: 0.8788577318191528, acc.: 51.0514497756958%] [G loss: [array(0.8851116, dtype=float32), array(0.8851116, dtype=float32), array(0.5069444, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246ms/step\n",
      "36 [D loss: 0.8883736729621887, acc.: 51.02276802062988%] [G loss: [array(0.8946204, dtype=float32), array(0.8946204, dtype=float32), array(0.5067568, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step\n",
      "37 [D loss: 0.8976209163665771, acc.: 50.995612144470215%] [G loss: [array(0.90371776, dtype=float32), array(0.90371776, dtype=float32), array(0.5065789, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step\n",
      "38 [D loss: 0.906583845615387, acc.: 50.969862937927246%] [G loss: [array(0.9125398, dtype=float32), array(0.9125398, dtype=float32), array(0.50641024, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step\n",
      "39 [D loss: 0.9153783917427063, acc.: 50.94541311264038%] [G loss: [array(0.9213339, dtype=float32), array(0.9213339, dtype=float32), array(0.50625, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step\n",
      "40 [D loss: 0.9240361452102661, acc.: 50.9221613407135%] [G loss: [array(0.9298376, dtype=float32), array(0.9298376, dtype=float32), array(0.50609756, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step\n",
      "41 [D loss: 0.9326265454292297, acc.: 50.9000301361084%] [G loss: [array(0.9385743, dtype=float32), array(0.9385743, dtype=float32), array(0.50595236, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 314ms/step\n",
      "42 [D loss: 0.9411087036132812, acc.: 50.87893009185791%] [G loss: [array(0.9468563, dtype=float32), array(0.9468563, dtype=float32), array(0.50581396, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step\n",
      "43 [D loss: 0.9491919279098511, acc.: 50.85880756378174%] [G loss: [array(0.9547462, dtype=float32), array(0.9547462, dtype=float32), array(0.5056818, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272ms/step\n",
      "44 [D loss: 0.9570897817611694, acc.: 50.8395791053772%] [G loss: [array(0.9626766, dtype=float32), array(0.9626766, dtype=float32), array(0.50555557, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 370ms/step\n",
      "45 [D loss: 0.9650963544845581, acc.: 50.82119107246399%] [G loss: [array(0.97076863, dtype=float32), array(0.97076863, dtype=float32), array(0.5054348, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step\n",
      "46 [D loss: 0.9730373620986938, acc.: 50.803589820861816%] [G loss: [array(0.9785973, dtype=float32), array(0.9785973, dtype=float32), array(0.5053192, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250ms/step\n",
      "47 [D loss: 0.9808729887008667, acc.: 50.786733627319336%] [G loss: [array(0.98643136, dtype=float32), array(0.98643136, dtype=float32), array(0.5052083, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step\n",
      "48 [D loss: 0.9884552955627441, acc.: 50.77056884765625%] [G loss: [array(0.99378145, dtype=float32), array(0.99378145, dtype=float32), array(0.50510204, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step\n",
      "49 [D loss: 0.9958924651145935, acc.: 50.75504779815674%] [G loss: [array(1.0012851, dtype=float32), array(1.0012851, dtype=float32), array(0.505, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246ms/step\n",
      "50 [D loss: 1.0033071041107178, acc.: 50.74014663696289%] [G loss: [array(1.0086824, dtype=float32), array(1.0086824, dtype=float32), array(0.50490195, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step\n",
      "51 [D loss: 1.0106147527694702, acc.: 50.725823640823364%] [G loss: [array(1.015862, dtype=float32), array(1.015862, dtype=float32), array(0.5048077, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step\n",
      "52 [D loss: 1.0178492069244385, acc.: 50.712037086486816%] [G loss: [array(1.0231553, dtype=float32), array(1.0231553, dtype=float32), array(0.504717, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272ms/step\n",
      "53 [D loss: 1.0248405933380127, acc.: 50.698769092559814%] [G loss: [array(1.0298685, dtype=float32), array(1.0298685, dtype=float32), array(0.5046296, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step\n",
      "54 [D loss: 1.031673789024353, acc.: 50.68598985671997%] [G loss: [array(1.0368136, dtype=float32), array(1.0368136, dtype=float32), array(0.50454545, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 248ms/step\n",
      "55 [D loss: 1.0384666919708252, acc.: 50.67366361618042%] [G loss: [array(1.0434433, dtype=float32), array(1.0434433, dtype=float32), array(0.50446427, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290ms/step\n",
      "56 [D loss: 1.0451278686523438, acc.: 50.66177845001221%] [G loss: [array(1.0501356, dtype=float32), array(1.0501356, dtype=float32), array(0.50438595, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step\n",
      "57 [D loss: 1.0517175197601318, acc.: 50.65029859542847%] [G loss: [array(1.0566473, dtype=float32), array(1.0566473, dtype=float32), array(0.50431037, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240ms/step\n",
      "58 [D loss: 1.05809485912323, acc.: 50.639212131500244%] [G loss: [array(1.0628843, dtype=float32), array(1.0628843, dtype=float32), array(0.5042373, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step\n",
      "59 [D loss: 1.0643466711044312, acc.: 50.628501176834106%] [G loss: [array(1.0691518, dtype=float32), array(1.0691518, dtype=float32), array(0.50416666, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step\n",
      "60 [D loss: 1.0706218481063843, acc.: 50.618141889572144%] [G loss: [array(1.0754415, dtype=float32), array(1.0754415, dtype=float32), array(0.50409836, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274ms/step\n",
      "61 [D loss: 1.0769681930541992, acc.: 50.60811638832092%] [G loss: [array(1.0818298, dtype=float32), array(1.0818298, dtype=float32), array(0.50403225, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step\n",
      "62 [D loss: 1.0831618309020996, acc.: 50.59841275215149%] [G loss: [array(1.0878204, dtype=float32), array(1.0878204, dtype=float32), array(0.50396824, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293ms/step\n",
      "63 [D loss: 1.0891636610031128, acc.: 50.58901309967041%] [G loss: [array(1.0938349, dtype=float32), array(1.0938349, dtype=float32), array(0.50390625, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step\n",
      "64 [D loss: 1.0951433181762695, acc.: 50.57990550994873%] [G loss: [array(1.0997757, dtype=float32), array(1.0997757, dtype=float32), array(0.50384617, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426ms/step\n",
      "65 [D loss: 1.101083517074585, acc.: 50.57107210159302%] [G loss: [array(1.1057001, dtype=float32), array(1.1057001, dtype=float32), array(0.5037879, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421ms/step\n",
      "66 [D loss: 1.1069175004959106, acc.: 50.562506914138794%] [G loss: [array(1.1114346, dtype=float32), array(1.1114346, dtype=float32), array(0.50373137, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419ms/step\n",
      "67 [D loss: 1.1127054691314697, acc.: 50.55419206619263%] [G loss: [array(1.1172595, dtype=float32), array(1.1172595, dtype=float32), array(0.5036765, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 417ms/step\n",
      "68 [D loss: 1.1184494495391846, acc.: 50.54612159729004%] [G loss: [array(1.1229421, dtype=float32), array(1.1229421, dtype=float32), array(0.5036232, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402ms/step\n",
      "69 [D loss: 1.124066710472107, acc.: 50.538283586502075%] [G loss: [array(1.1284935, dtype=float32), array(1.1284935, dtype=float32), array(0.50357145, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405ms/step\n",
      "70 [D loss: 1.129582405090332, acc.: 50.53066611289978%] [G loss: [array(1.1339523, dtype=float32), array(1.1339523, dtype=float32), array(0.50352114, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step\n",
      "71 [D loss: 1.1350762844085693, acc.: 50.5232572555542%] [G loss: [array(1.1394784, dtype=float32), array(1.1394784, dtype=float32), array(0.5034722, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401ms/step\n",
      "72 [D loss: 1.1406216621398926, acc.: 50.51605701446533%] [G loss: [array(1.1450285, dtype=float32), array(1.1450285, dtype=float32), array(0.50342464, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404ms/step\n",
      "73 [D loss: 1.1461098194122314, acc.: 50.5090594291687%] [G loss: [array(1.1504482, dtype=float32), array(1.1504482, dtype=float32), array(0.5033784, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421ms/step\n",
      "74 [D loss: 1.1514098644256592, acc.: 50.5022406578064%] [G loss: [array(1.1556345, dtype=float32), array(1.1556345, dtype=float32), array(0.50333333, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 416ms/step\n",
      "75 [D loss: 1.1566743850708008, acc.: 50.49560070037842%] [G loss: [array(1.160979, dtype=float32), array(1.160979, dtype=float32), array(0.50328946, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 416ms/step\n",
      "76 [D loss: 1.1619548797607422, acc.: 50.48913359642029%] [G loss: [array(1.1661814, dtype=float32), array(1.1661814, dtype=float32), array(0.5032467, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421ms/step\n",
      "77 [D loss: 1.1671156883239746, acc.: 50.48283338546753%] [G loss: [array(1.1712688, dtype=float32), array(1.1712688, dtype=float32), array(0.5032051, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424ms/step\n",
      "78 [D loss: 1.1722302436828613, acc.: 50.476694107055664%] [G loss: [array(1.1764086, dtype=float32), array(1.1764086, dtype=float32), array(0.5031645, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456ms/step\n",
      "79 [D loss: 1.1773433685302734, acc.: 50.47071576118469%] [G loss: [array(1.1814718, dtype=float32), array(1.1814718, dtype=float32), array(0.503125, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 417ms/step\n",
      "80 [D loss: 1.182321548461914, acc.: 50.46488046646118%] [G loss: [array(1.186374, dtype=float32), array(1.186374, dtype=float32), array(0.50308645, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408ms/step\n",
      "81 [D loss: 1.1872628927230835, acc.: 50.45918822288513%] [G loss: [array(1.1913271, dtype=float32), array(1.1913271, dtype=float32), array(0.5030488, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403ms/step\n",
      "82 [D loss: 1.1921330690383911, acc.: 50.453633069992065%] [G loss: [array(1.1961168, dtype=float32), array(1.1961168, dtype=float32), array(0.50301206, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401ms/step\n",
      "83 [D loss: 1.1969599723815918, acc.: 50.448209047317505%] [G loss: [array(1.2009562, dtype=float32), array(1.2009562, dtype=float32), array(0.5029762, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424ms/step\n",
      "84 [D loss: 1.2017136812210083, acc.: 50.44291615486145%] [G loss: [array(1.205662, dtype=float32), array(1.205662, dtype=float32), array(0.5029412, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 432ms/step\n",
      "85 [D loss: 1.206437587738037, acc.: 50.437748432159424%] [G loss: [array(1.21037, dtype=float32), array(1.21037, dtype=float32), array(0.502907, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333ms/step\n",
      "86 [D loss: 1.2111327648162842, acc.: 50.43269395828247%] [G loss: [array(1.2150244, dtype=float32), array(1.2150244, dtype=float32), array(0.50287354, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264ms/step\n",
      "87 [D loss: 1.2157584428787231, acc.: 50.42775869369507%] [G loss: [array(1.2196287, dtype=float32), array(1.2196287, dtype=float32), array(0.50284094, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step\n",
      "88 [D loss: 1.2203327417373657, acc.: 50.42293667793274%] [G loss: [array(1.2241447, dtype=float32), array(1.2241447, dtype=float32), array(0.502809, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305ms/step\n",
      "89 [D loss: 1.2247899770736694, acc.: 50.41821599006653%] [G loss: [array(1.2285577, dtype=float32), array(1.2285577, dtype=float32), array(0.50277776, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step\n",
      "90 [D loss: 1.2292729616165161, acc.: 50.41360855102539%] [G loss: [array(1.233071, dtype=float32), array(1.233071, dtype=float32), array(0.50274724, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411ms/step\n",
      "91 [D loss: 1.2337286472320557, acc.: 50.409090518951416%] [G loss: [array(1.2374712, dtype=float32), array(1.2374712, dtype=float32), array(0.5027174, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 506ms/step\n",
      "92 [D loss: 1.238109827041626, acc.: 50.40467977523804%] [G loss: [array(1.2418152, dtype=float32), array(1.2418152, dtype=float32), array(0.50268817, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411ms/step\n",
      "93 [D loss: 1.2424101829528809, acc.: 50.40035843849182%] [G loss: [array(1.2460945, dtype=float32), array(1.2460945, dtype=float32), array(0.50265956, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412ms/step\n",
      "94 [D loss: 1.2466926574707031, acc.: 50.396132469177246%] [G loss: [array(1.2503632, dtype=float32), array(1.2503632, dtype=float32), array(0.5026316, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412ms/step\n",
      "95 [D loss: 1.2510184049606323, acc.: 50.391989946365356%] [G loss: [array(1.2547244, dtype=float32), array(1.2547244, dtype=float32), array(0.5026042, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407ms/step\n",
      "96 [D loss: 1.2552987337112427, acc.: 50.38793087005615%] [G loss: [array(1.2589155, dtype=float32), array(1.2589155, dtype=float32), array(0.5025773, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408ms/step\n",
      "97 [D loss: 1.2595700025558472, acc.: 50.38396120071411%] [G loss: [array(1.2632443, dtype=float32), array(1.2632443, dtype=float32), array(0.502551, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457ms/step\n",
      "98 [D loss: 1.263769507408142, acc.: 50.380074977874756%] [G loss: [array(1.2673271, dtype=float32), array(1.2673271, dtype=float32), array(0.50252527, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step\n",
      "99 [D loss: 1.26788330078125, acc.: 50.37626028060913%] [G loss: [array(1.27146, dtype=float32), array(1.27146, dtype=float32), array(0.5025, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 423ms/step\n",
      "100 [D loss: 1.2720155715942383, acc.: 50.372517108917236%] [G loss: [array(1.2755754, dtype=float32), array(1.2755754, dtype=float32), array(0.50247526, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step\n",
      "Generated level saved to ./generated_level_100.txt\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458ms/step\n",
      "101 [D loss: 1.2760951519012451, acc.: 50.36885738372803%] [G loss: [array(1.2796098, dtype=float32), array(1.2796098, dtype=float32), array(0.502451, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step\n",
      "102 [D loss: 1.2801451683044434, acc.: 50.365257263183594%] [G loss: [array(1.2836584, dtype=float32), array(1.2836584, dtype=float32), array(0.50242716, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step\n",
      "103 [D loss: 1.284178614616394, acc.: 50.361740589141846%] [G loss: [array(1.2876636, dtype=float32), array(1.2876636, dtype=float32), array(0.50240386, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477ms/step\n",
      "104 [D loss: 1.2881351709365845, acc.: 50.35828351974487%] [G loss: [array(1.2915831, dtype=float32), array(1.2915831, dtype=float32), array(0.50238097, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 433ms/step\n",
      "105 [D loss: 1.2920567989349365, acc.: 50.35489201545715%] [G loss: [array(1.2954797, dtype=float32), array(1.2954797, dtype=float32), array(0.5023585, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408ms/step\n",
      "106 [D loss: 1.2959024906158447, acc.: 50.35156011581421%] [G loss: [array(1.2992829, dtype=float32), array(1.2992829, dtype=float32), array(0.50233644, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405ms/step\n",
      "107 [D loss: 1.2997229099273682, acc.: 50.348299741744995%] [G loss: [array(1.3030963, dtype=float32), array(1.3030963, dtype=float32), array(0.5023148, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465ms/step\n",
      "108 [D loss: 1.3035337924957275, acc.: 50.34509301185608%] [G loss: [array(1.3069047, dtype=float32), array(1.3069047, dtype=float32), array(0.5022936, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446ms/step\n",
      "109 [D loss: 1.307304859161377, acc.: 50.34194588661194%] [G loss: [array(1.3106256, dtype=float32), array(1.3106256, dtype=float32), array(0.5022727, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 416ms/step\n",
      "110 [D loss: 1.3110096454620361, acc.: 50.33885836601257%] [G loss: [array(1.3143121, dtype=float32), array(1.3143121, dtype=float32), array(0.5022523, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426ms/step\n",
      "111 [D loss: 1.3146817684173584, acc.: 50.335824489593506%] [G loss: [array(1.3179585, dtype=float32), array(1.3179585, dtype=float32), array(0.50223213, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 434ms/step\n",
      "112 [D loss: 1.3183717727661133, acc.: 50.332844257354736%] [G loss: [array(1.3216798, dtype=float32), array(1.3216798, dtype=float32), array(0.5022124, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step\n",
      "113 [D loss: 1.3220694065093994, acc.: 50.32991170883179%] [G loss: [array(1.3253596, dtype=float32), array(1.3253596, dtype=float32), array(0.502193, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 342ms/step\n",
      "114 [D loss: 1.3257418870925903, acc.: 50.32703876495361%] [G loss: [array(1.3290005, dtype=float32), array(1.3290005, dtype=float32), array(0.5021739, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step\n",
      "115 [D loss: 1.3293650150299072, acc.: 50.32421350479126%] [G loss: [array(1.3325927, dtype=float32), array(1.3325927, dtype=float32), array(0.5021552, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276ms/step\n",
      "116 [D loss: 1.332953691482544, acc.: 50.32142996788025%] [G loss: [array(1.3361648, dtype=float32), array(1.3361648, dtype=float32), array(0.50213677, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step\n",
      "117 [D loss: 1.33652925491333, acc.: 50.31869411468506%] [G loss: [array(1.3397349, dtype=float32), array(1.3397349, dtype=float32), array(0.50211865, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328ms/step\n",
      "118 [D loss: 1.3400917053222656, acc.: 50.316011905670166%] [G loss: [array(1.3432801, dtype=float32), array(1.3432801, dtype=float32), array(0.5021008, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419ms/step\n",
      "119 [D loss: 1.3435944318771362, acc.: 50.313377380371094%] [G loss: [array(1.346731, dtype=float32), array(1.346731, dtype=float32), array(0.50208336, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 581ms/step\n",
      "120 [D loss: 1.347024917602539, acc.: 50.31077861785889%] [G loss: [array(1.3501552, dtype=float32), array(1.3501552, dtype=float32), array(0.50206614, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421ms/step\n",
      "121 [D loss: 1.3504772186279297, acc.: 50.30822157859802%] [G loss: [array(1.3536134, dtype=float32), array(1.3536134, dtype=float32), array(0.5020492, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408ms/step\n",
      "122 [D loss: 1.3539326190948486, acc.: 50.3057062625885%] [G loss: [array(1.3570606, dtype=float32), array(1.3570606, dtype=float32), array(0.5020325, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419ms/step\n",
      "123 [D loss: 1.3573418855667114, acc.: 50.30323266983032%] [G loss: [array(1.360428, dtype=float32), array(1.360428, dtype=float32), array(0.5020161, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399ms/step\n",
      "124 [D loss: 1.3607020378112793, acc.: 50.300800800323486%] [G loss: [array(1.3637629, dtype=float32), array(1.3637629, dtype=float32), array(0.502, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407ms/step\n",
      "125 [D loss: 1.3640217781066895, acc.: 50.298404693603516%] [G loss: [array(1.3670678, dtype=float32), array(1.3670678, dtype=float32), array(0.5019841, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 432ms/step\n",
      "126 [D loss: 1.3673391342163086, acc.: 50.296056270599365%] [G loss: [array(1.3703887, dtype=float32), array(1.3703887, dtype=float32), array(0.5019685, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411ms/step\n",
      "127 [D loss: 1.3706426620483398, acc.: 50.293731689453125%] [G loss: [array(1.3736566, dtype=float32), array(1.3736566, dtype=float32), array(0.5019531, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 423ms/step\n",
      "128 [D loss: 1.3738961219787598, acc.: 50.291454792022705%] [G loss: [array(1.3768915, dtype=float32), array(1.3768915, dtype=float32), array(0.501938, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470ms/step\n",
      "129 [D loss: 1.3771260976791382, acc.: 50.289201736450195%] [G loss: [array(1.3800985, dtype=float32), array(1.3800985, dtype=float32), array(0.5019231, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step\n",
      "130 [D loss: 1.380337119102478, acc.: 50.286996364593506%] [G loss: [array(1.3832898, dtype=float32), array(1.3832898, dtype=float32), array(0.5019084, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390ms/step\n",
      "131 [D loss: 1.3835082054138184, acc.: 50.28481483459473%] [G loss: [array(1.3864553, dtype=float32), array(1.3864553, dtype=float32), array(0.50189394, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493ms/step\n",
      "132 [D loss: 1.3866770267486572, acc.: 50.282663106918335%] [G loss: [array(1.3896098, dtype=float32), array(1.3896098, dtype=float32), array(0.5018797, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409ms/step\n",
      "133 [D loss: 1.389841079711914, acc.: 50.28054714202881%] [G loss: [array(1.3927864, dtype=float32), array(1.3927864, dtype=float32), array(0.5018657, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step\n",
      "134 [D loss: 1.3929693698883057, acc.: 50.27846693992615%] [G loss: [array(1.3958403, dtype=float32), array(1.3958403, dtype=float32), array(0.50185186, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402ms/step\n",
      "135 [D loss: 1.3960686922073364, acc.: 50.2764105796814%] [G loss: [array(1.398991, dtype=float32), array(1.398991, dtype=float32), array(0.5018382, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408ms/step\n",
      "136 [D loss: 1.399184226989746, acc.: 50.27438998222351%] [G loss: [array(1.402059, dtype=float32), array(1.402059, dtype=float32), array(0.5018248, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 416ms/step\n",
      "137 [D loss: 1.4022184610366821, acc.: 50.27239918708801%] [G loss: [array(1.405046, dtype=float32), array(1.405046, dtype=float32), array(0.5018116, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401ms/step\n",
      "138 [D loss: 1.4052174091339111, acc.: 50.2704381942749%] [G loss: [array(1.4080454, dtype=float32), array(1.4080454, dtype=float32), array(0.50179857, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412ms/step\n",
      "139 [D loss: 1.4082307815551758, acc.: 50.268495082855225%] [G loss: [array(1.4110732, dtype=float32), array(1.4110732, dtype=float32), array(0.5017857, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404ms/step\n",
      "140 [D loss: 1.411224365234375, acc.: 50.26658773422241%] [G loss: [array(1.414034, dtype=float32), array(1.414034, dtype=float32), array(0.50177306, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388ms/step\n",
      "141 [D loss: 1.4141895771026611, acc.: 50.26470422744751%] [G loss: [array(1.4169854, dtype=float32), array(1.4169854, dtype=float32), array(0.50176054, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step\n",
      "142 [D loss: 1.4171607494354248, acc.: 50.262850522994995%] [G loss: [array(1.4199607, dtype=float32), array(1.4199607, dtype=float32), array(0.50174826, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step\n",
      "143 [D loss: 1.4201158285140991, acc.: 50.26102066040039%] [G loss: [array(1.4228826, dtype=float32), array(1.4228826, dtype=float32), array(0.5017361, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step\n",
      "144 [D loss: 1.4230365753173828, acc.: 50.259220600128174%] [G loss: [array(1.4257903, dtype=float32), array(1.4257903, dtype=float32), array(0.5017241, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 289ms/step\n",
      "145 [D loss: 1.4259347915649414, acc.: 50.25743842124939%] [G loss: [array(1.4287012, dtype=float32), array(1.4287012, dtype=float32), array(0.5017123, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step\n",
      "146 [D loss: 1.4288008213043213, acc.: 50.255680084228516%] [G loss: [array(1.4315088, dtype=float32), array(1.4315088, dtype=float32), array(0.5017007, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250ms/step\n",
      "147 [D loss: 1.431634545326233, acc.: 50.25395154953003%] [G loss: [array(1.4343576, dtype=float32), array(1.4343576, dtype=float32), array(0.5016892, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264ms/step\n",
      "148 [D loss: 1.4344532489776611, acc.: 50.25224685668945%] [G loss: [array(1.4371414, dtype=float32), array(1.4371414, dtype=float32), array(0.5016779, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step\n",
      "149 [D loss: 1.4372483491897583, acc.: 50.25055408477783%] [G loss: [array(1.4399374, dtype=float32), array(1.4399374, dtype=float32), array(0.50166667, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step\n",
      "150 [D loss: 1.4400174617767334, acc.: 50.248897075653076%] [G loss: [array(1.4426799, dtype=float32), array(1.4426799, dtype=float32), array(0.50165564, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step\n",
      "151 [D loss: 1.4428048133850098, acc.: 50.247251987457275%] [G loss: [array(1.4454848, dtype=float32), array(1.4454848, dtype=float32), array(0.50164473, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278ms/step\n",
      "152 [D loss: 1.4455702304840088, acc.: 50.245630741119385%] [G loss: [array(1.4482138, dtype=float32), array(1.4482138, dtype=float32), array(0.501634, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step\n",
      "153 [D loss: 1.4483065605163574, acc.: 50.244033336639404%] [G loss: [array(1.4509318, dtype=float32), array(1.4509318, dtype=float32), array(0.5016234, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step\n",
      "154 [D loss: 1.4510337114334106, acc.: 50.242459774017334%] [G loss: [array(1.4536738, dtype=float32), array(1.4536738, dtype=float32), array(0.5016129, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step\n",
      "155 [D loss: 1.4537482261657715, acc.: 50.24089813232422%] [G loss: [array(1.4563602, dtype=float32), array(1.4563602, dtype=float32), array(0.5016026, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step\n",
      "156 [D loss: 1.4564522504806519, acc.: 50.239360332489014%] [G loss: [array(1.4590684, dtype=float32), array(1.4590684, dtype=float32), array(0.50159234, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step\n",
      "157 [D loss: 1.4591553211212158, acc.: 50.23784637451172%] [G loss: [array(1.4617585, dtype=float32), array(1.4617585, dtype=float32), array(0.50158226, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step\n",
      "158 [D loss: 1.4618293046951294, acc.: 50.23634433746338%] [G loss: [array(1.4643978, dtype=float32), array(1.4643978, dtype=float32), array(0.5015723, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292ms/step\n",
      "159 [D loss: 1.464483380317688, acc.: 50.23486614227295%] [G loss: [array(1.4670689, dtype=float32), array(1.4670689, dtype=float32), array(0.5015625, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458ms/step\n",
      "160 [D loss: 1.4671251773834229, acc.: 50.233399868011475%] [G loss: [array(1.4696901, dtype=float32), array(1.4696901, dtype=float32), array(0.5015528, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419ms/step\n",
      "161 [D loss: 1.4697751998901367, acc.: 50.23195743560791%] [G loss: [array(1.4723389, dtype=float32), array(1.4723389, dtype=float32), array(0.5015432, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425ms/step\n",
      "162 [D loss: 1.472381591796875, acc.: 50.23053288459778%] [G loss: [array(1.474912, dtype=float32), array(1.474912, dtype=float32), array(0.50153375, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408ms/step\n",
      "163 [D loss: 1.4749723672866821, acc.: 50.2291202545166%] [G loss: [array(1.4775056, dtype=float32), array(1.4775056, dtype=float32), array(0.5015244, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398ms/step\n",
      "164 [D loss: 1.4775506258010864, acc.: 50.22773742675781%] [G loss: [array(1.4800615, dtype=float32), array(1.4800615, dtype=float32), array(0.50151515, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396ms/step\n",
      "165 [D loss: 1.480109453201294, acc.: 50.22635459899902%] [G loss: [array(1.4826142, dtype=float32), array(1.4826142, dtype=float32), array(0.50150603, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 530ms/step\n",
      "166 [D loss: 1.4826462268829346, acc.: 50.22500157356262%] [G loss: [array(1.4851419, dtype=float32), array(1.4851419, dtype=float32), array(0.50149703, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438ms/step\n",
      "167 [D loss: 1.4851739406585693, acc.: 50.223660469055176%] [G loss: [array(1.4876589, dtype=float32), array(1.4876589, dtype=float32), array(0.5014881, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 434ms/step\n",
      "168 [D loss: 1.4877029657363892, acc.: 50.222331285476685%] [G loss: [array(1.4901787, dtype=float32), array(1.4901787, dtype=float32), array(0.50147927, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441ms/step\n",
      "169 [D loss: 1.490224838256836, acc.: 50.221019983291626%] [G loss: [array(1.4926943, dtype=float32), array(1.4926943, dtype=float32), array(0.50147057, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443ms/step\n",
      "170 [D loss: 1.4927175045013428, acc.: 50.2197265625%] [G loss: [array(1.4951566, dtype=float32), array(1.4951566, dtype=float32), array(0.501462, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 524ms/step\n",
      "171 [D loss: 1.495201587677002, acc.: 50.21844506263733%] [G loss: [array(1.497661, dtype=float32), array(1.497661, dtype=float32), array(0.50145346, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454ms/step\n",
      "172 [D loss: 1.4976699352264404, acc.: 50.21718740463257%] [G loss: [array(1.5000901, dtype=float32), array(1.5000901, dtype=float32), array(0.5014451, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427ms/step\n",
      "173 [D loss: 1.5001143217086792, acc.: 50.21592974662781%] [G loss: [array(1.5025405, dtype=float32), array(1.5025405, dtype=float32), array(0.50143677, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426ms/step\n",
      "174 [D loss: 1.5025203227996826, acc.: 50.21469593048096%] [G loss: [array(1.5049087, dtype=float32), array(1.5049087, dtype=float32), array(0.50142854, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437ms/step\n",
      "175 [D loss: 1.50490403175354, acc.: 50.213468074798584%] [G loss: [array(1.5072922, dtype=float32), array(1.5072922, dtype=float32), array(0.50142044, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465ms/step\n",
      "176 [D loss: 1.5072784423828125, acc.: 50.21226406097412%] [G loss: [array(1.5096546, dtype=float32), array(1.5096546, dtype=float32), array(0.50141245, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step\n",
      "177 [D loss: 1.5096535682678223, acc.: 50.21107196807861%] [G loss: [array(1.5120152, dtype=float32), array(1.5120152, dtype=float32), array(0.5014045, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407ms/step\n",
      "178 [D loss: 1.5120034217834473, acc.: 50.20989179611206%] [G loss: [array(1.5143646, dtype=float32), array(1.5143646, dtype=float32), array(0.50139666, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500ms/step\n",
      "179 [D loss: 1.5143609046936035, acc.: 50.20872354507446%] [G loss: [array(1.5167185, dtype=float32), array(1.5167185, dtype=float32), array(0.5013889, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426ms/step\n",
      "180 [D loss: 1.5167086124420166, acc.: 50.20756721496582%] [G loss: [array(1.519058, dtype=float32), array(1.519058, dtype=float32), array(0.5013812, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step\n",
      "181 [D loss: 1.519054651260376, acc.: 50.20642280578613%] [G loss: [array(1.5213932, dtype=float32), array(1.5213932, dtype=float32), array(0.50137365, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411ms/step\n",
      "182 [D loss: 1.5213696956634521, acc.: 50.2052903175354%] [G loss: [array(1.5236808, dtype=float32), array(1.5236808, dtype=float32), array(0.50136614, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439ms/step\n",
      "183 [D loss: 1.523663878440857, acc.: 50.20416975021362%] [G loss: [array(1.5259713, dtype=float32), array(1.5259713, dtype=float32), array(0.5013587, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424ms/step\n",
      "184 [D loss: 1.5259480476379395, acc.: 50.203073024749756%] [G loss: [array(1.5282538, dtype=float32), array(1.5282538, dtype=float32), array(0.50135136, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446ms/step\n",
      "185 [D loss: 1.5282421112060547, acc.: 50.20197629928589%] [G loss: [array(1.5305493, dtype=float32), array(1.5305493, dtype=float32), array(0.5013441, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419ms/step\n",
      "186 [D loss: 1.5305233001708984, acc.: 50.20089149475098%] [G loss: [array(1.5328174, dtype=float32), array(1.5328174, dtype=float32), array(0.5013369, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419ms/step\n",
      "187 [D loss: 1.5327887535095215, acc.: 50.19981861114502%] [G loss: [array(1.5350682, dtype=float32), array(1.5350682, dtype=float32), array(0.5013298, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step\n",
      "188 [D loss: 1.5350418090820312, acc.: 50.198763608932495%] [G loss: [array(1.5373158, dtype=float32), array(1.5373158, dtype=float32), array(0.50132275, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276ms/step\n",
      "189 [D loss: 1.5372979640960693, acc.: 50.19771456718445%] [G loss: [array(1.5395744, dtype=float32), array(1.5395744, dtype=float32), array(0.5013158, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step\n",
      "190 [D loss: 1.5395481586456299, acc.: 50.196683406829834%] [G loss: [array(1.541815, dtype=float32), array(1.541815, dtype=float32), array(0.5013089, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288ms/step\n",
      "191 [D loss: 1.5417622327804565, acc.: 50.19565224647522%] [G loss: [array(1.5439931, dtype=float32), array(1.5439931, dtype=float32), array(0.50130206, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step\n",
      "192 [D loss: 1.5439571142196655, acc.: 50.19463300704956%] [G loss: [array(1.5461974, dtype=float32), array(1.5461974, dtype=float32), array(0.5012953, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_3372\\48845432.py:161: SyntaxWarning: invalid escape sequence '\\T'\n",
      "  directory_path = '.\\TheVGLC\\Super Mario Bros\\Processed'\n"
     ]
    },
    {
     "ename": "DecodeError",
     "evalue": "Error parsing message",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDecodeError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 178\u001b[0m\n\u001b[0;32m    175\u001b[0m gan \u001b[38;5;241m=\u001b[39m compile_gan(generator, discriminator)\n\u001b[0;32m    177\u001b[0m \u001b[38;5;66;03m# Train the GAN\u001b[39;00m\n\u001b[1;32m--> 178\u001b[0m \u001b[43mtrain_gan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiscriminator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_levels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlatent_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlatent_dim\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 145\u001b[0m, in \u001b[0;36mtrain_gan\u001b[1;34m(generator, discriminator, gan, data, epochs, batch_size, latent_dim)\u001b[0m\n\u001b[0;32m    143\u001b[0m fake_labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((half_batch, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m    144\u001b[0m d_loss_real \u001b[38;5;241m=\u001b[39m discriminator\u001b[38;5;241m.\u001b[39mtrain_on_batch(real_levels, real_labels)\n\u001b[1;32m--> 145\u001b[0m d_loss_fake \u001b[38;5;241m=\u001b[39m \u001b[43mdiscriminator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_on_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerated_levels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfake_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    146\u001b[0m d_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39madd(d_loss_real, d_loss_fake)\n\u001b[0;32m    148\u001b[0m \u001b[38;5;66;03m# Train generator\u001b[39;00m\n",
      "File \u001b[1;32md:\\Deep Learning\\myenv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:544\u001b[0m, in \u001b[0;36mTensorFlowTrainer.train_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, return_dict)\u001b[0m\n\u001b[0;32m    541\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdata\u001b[39m():\n\u001b[0;32m    542\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m (x, y, sample_weight)\n\u001b[1;32m--> 544\u001b[0m logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    545\u001b[0m logs \u001b[38;5;241m=\u001b[39m tree\u001b[38;5;241m.\u001b[39mmap_structure(\u001b[38;5;28;01mlambda\u001b[39;00m x: np\u001b[38;5;241m.\u001b[39marray(x), logs)\n\u001b[0;32m    546\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_dict:\n",
      "File \u001b[1;32md:\\Deep Learning\\myenv\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32md:\\Deep Learning\\myenv\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1461\u001b[0m, in \u001b[0;36mContext.get_function_def\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1459\u001b[0m     proto_data \u001b[38;5;241m=\u001b[39m pywrap_tf_session\u001b[38;5;241m.\u001b[39mTF_GetBuffer(buffer_)\n\u001b[0;32m   1460\u001b[0m   function_def \u001b[38;5;241m=\u001b[39m function_pb2\u001b[38;5;241m.\u001b[39mFunctionDef()\n\u001b[1;32m-> 1461\u001b[0m   \u001b[43mfunction_def\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mParseFromString\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproto_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1462\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1463\u001b[0m   function_def \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_ContextGetFunctionDefNoSerialization(\n\u001b[0;32m   1464\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle, name\n\u001b[0;32m   1465\u001b[0m   )\n",
      "\u001b[1;31mDecodeError\u001b[0m: Error parsing message"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Dense, Reshape, Flatten, Input, BatchNormalization, LeakyReLU, UpSampling2D, Conv2D\n",
    "from keras.optimizers import Adam\n",
    "import os\n",
    "\n",
    "# Set dimensions\n",
    "latent_dim = 100\n",
    "max_height, max_width = 16, 372  # Adjust to match your dataset\n",
    "level_shape = (max_height, max_width, 1)\n",
    "\n",
    "# Create character mappings from directory\n",
    "def create_char_mappings_from_directory(directory_path):\n",
    "    char_set = set()\n",
    "\n",
    "    for file_name in os.listdir(directory_path):\n",
    "        file_path = os.path.join(directory_path, file_name)\n",
    "\n",
    "        # Skip if the file_path is a directory\n",
    "        if os.path.isdir(file_path):\n",
    "            continue\n",
    "\n",
    "        with open(file_path, 'r') as file:\n",
    "            for line in file:\n",
    "                char_set.update(line.strip())\n",
    "\n",
    "    char_to_int = {char: idx for idx, char in enumerate(sorted(char_set))}\n",
    "    int_to_char = {idx: char for char, idx in char_to_int.items()}\n",
    "\n",
    "    return char_to_int, int_to_char\n",
    "\n",
    "# Preprocess levels\n",
    "def preprocess_levels(directory_path, max_width, max_height, char_to_int):\n",
    "    levels = []\n",
    "\n",
    "    for file_name in os.listdir(directory_path):\n",
    "        file_path = os.path.join(directory_path, file_name)\n",
    "\n",
    "        # Skip if the file_path is a directory\n",
    "        if os.path.isdir(file_path):\n",
    "            continue\n",
    "\n",
    "        level = []\n",
    "        with open(file_path, 'r') as file:\n",
    "            for line in file:\n",
    "                row = [char_to_int.get(char, -1) for char in line.strip()]\n",
    "                # Pad or truncate rows to max_width\n",
    "                if len(row) < max_width:\n",
    "                    row.extend([-1] * (max_width - len(row)))\n",
    "                else:\n",
    "                    row = row[:max_width]\n",
    "                level.append(row)\n",
    "\n",
    "        # Pad or truncate levels to max_height\n",
    "        if len(level) < max_height:\n",
    "            level.extend([[-1] * max_width] * (max_height - len(level)))\n",
    "        else:\n",
    "            level = level[:max_height]\n",
    "\n",
    "        levels.append(np.array(level))\n",
    "\n",
    "    return np.array(levels)\n",
    "\n",
    "\n",
    "# Build generator\n",
    "def build_generator(latent_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128 * (max_height // 4) * (max_width // 4), activation=\"relu\", input_dim=latent_dim))\n",
    "    model.add(Reshape((max_height // 4, max_width // 4, 128)))\n",
    "\n",
    "    # Upsample to (max_height // 2, max_width // 2, 128)\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    # Upsample to (max_height, max_width, 128)\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    # Final layer to match the shape of the output\n",
    "    model.add(Conv2D(1, kernel_size=3, padding=\"same\", activation='tanh'))\n",
    "    return model\n",
    "\n",
    "# Build discriminator\n",
    "def build_discriminator(level_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=level_shape))\n",
    "\n",
    "    model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "# Compile the GAN\n",
    "def compile_gan(generator, discriminator):\n",
    "    discriminator.compile(loss='binary_crossentropy', optimizer=Adam(0.0002, 0.5), metrics=['accuracy'])\n",
    "    discriminator.trainable = False\n",
    "\n",
    "    gan_input = Input(shape=(latent_dim,))\n",
    "    generated_level = generator(gan_input)\n",
    "    gan_output = discriminator(generated_level)\n",
    "\n",
    "    gan = Model(gan_input, gan_output)\n",
    "    gan.compile(loss='binary_crossentropy', optimizer=Adam(0.0002, 0.5))\n",
    "    return gan\n",
    "\n",
    "# Save generated levels to file\n",
    "def save_generated_levels(generator, epoch, latent_dim=100):\n",
    "    noise = np.random.normal(0, 1, (1, latent_dim))\n",
    "    gen_levels = generator.predict(noise)\n",
    "    gen_levels = np.squeeze(gen_levels)  # Remove single-dimensional entries\n",
    "    gen_levels_char = convert_to_char(gen_levels, int_to_char)\n",
    "    save_level_to_file(gen_levels_char, f\"./generated_level_{epoch}.txt\")\n",
    "\n",
    "def save_level_to_file(level, file_path):\n",
    "    with open(file_path, 'w') as f:\n",
    "        for row in level:\n",
    "            f.write(''.join(row) + '\\n')\n",
    "    print(f\"Generated level saved to {file_path}\")\n",
    "\n",
    "# Convert numeric levels to characters\n",
    "def convert_to_char(numeric_level, int_to_char):\n",
    "    return [[int_to_char.get(int(val), '?') for val in row] for row in numeric_level]\n",
    "\n",
    "# Train the GAN\n",
    "def train_gan(generator, discriminator, gan, data, epochs, batch_size, latent_dim):\n",
    "    half_batch = batch_size // 2\n",
    "    for epoch in range(epochs):\n",
    "        # Train discriminator\n",
    "        idx = np.random.randint(0, data.shape[0], half_batch)\n",
    "        real_levels = data[idx]\n",
    "        real_labels = np.ones((half_batch, 1))\n",
    "        noise = np.random.normal(0, 1, (half_batch, latent_dim))\n",
    "        generated_levels = generator.predict(noise)\n",
    "        fake_labels = np.zeros((half_batch, 1))\n",
    "        d_loss_real = discriminator.train_on_batch(real_levels, real_labels)\n",
    "        d_loss_fake = discriminator.train_on_batch(generated_levels, fake_labels)\n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "        # Train generator\n",
    "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "        valid_y = np.ones((batch_size, 1))\n",
    "        g_loss = gan.train_on_batch(noise, valid_y)\n",
    "\n",
    "        # Print the progress\n",
    "        print(f\"{epoch} [D loss: {d_loss[0]}, acc.: {d_loss[1]*100}%] [G loss: {g_loss}]\")\n",
    "\n",
    "        # If at save interval => save generated level samples\n",
    "        if epoch % 100 == 0:\n",
    "            save_generated_levels(generator, epoch)\n",
    "\n",
    "# Main execution\n",
    "directory_path = './Processed'\n",
    "char_to_int, int_to_char = create_char_mappings_from_directory(directory_path)\n",
    "num_classes = len(char_to_int)\n",
    "\n",
    "# Convert numeric levels to the format needed for the GAN\n",
    "numeric_levels = preprocess_levels(directory_path, max_width, max_height, char_to_int)\n",
    "numeric_levels = numeric_levels.reshape(-1, max_height, max_width, 1)\n",
    "\n",
    "# Normalize data to [-1, 1]\n",
    "numeric_levels = (numeric_levels.astype(np.float32) - num_classes / 2) / (num_classes / 2)\n",
    "\n",
    "# Create and compile models\n",
    "generator = build_generator(latent_dim)\n",
    "discriminator = build_discriminator(level_shape)\n",
    "gan = compile_gan(generator, discriminator)\n",
    "\n",
    "# Train the GAN\n",
    "train_gan(generator, discriminator, gan, numeric_levels, epochs=10000, batch_size=64, latent_dim=latent_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
